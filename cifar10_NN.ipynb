{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_lable(y, num_classes):\n",
    "    y_gt = np.zeros((len(y), num_classes))\n",
    "    for i in range(0, len(y)):\n",
    "        y_gt[i, y[i]] = 1\n",
    "    return y_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(theta, X):\n",
    "    return 1.0 / (1 + np.exp(-np.dot(X, theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigm_derivative(theta, X):\n",
    "    return h(theta, X) * (1 - h(theta, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_gt, y_pred):\n",
    "    cross_entropy_error = 0.0\n",
    "    for i in range(0, len(y_gt)):\n",
    "        for j in range(0, len(y_gt[i])):\n",
    "            cross_entropy_error -= (y_gt[i][j] * np.log(y_pred[i][j]) + (1 - y_gt[i][j]) * np.log(1 - y_pred[i][j]))\n",
    "    return cross_entropy_error / len(y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CEderivative(X, y_gt, y_pred):\n",
    "    return np.dot(y_pred - y_gt, X) / len(y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(thetas, X):\n",
    "    num_layers = thetas.shape[0]\n",
    "    outs = []\n",
    "    for t in range(0, num_layers): #проходим по всем слоям (все слои с сигмоидальной функцией активации)\n",
    "        if t == 0:\n",
    "            outs.append(np.array([h(thetas[t][:, i], X) for i in range(0, thetas[t].shape[1])]).T)\n",
    "        else:\n",
    "            outs.append(np.array([h(thetas[t][:, i], np.asarray(outs[t-1])) for i in range(0, thetas[t].shape[1])]).T)\n",
    "    return [out for out in outs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X, y_gt, thetas):\n",
    "    num_features = X.shape[1]\n",
    "    num_classes = y_gt.shape[1]\n",
    "    outs = forward(thetas, X)\n",
    "    num_layers = len(outs)\n",
    "    \n",
    "    d_theta = []\n",
    "    d_theta.append(np.zeros([num_features, outs[0].shape[1]]))\n",
    "    for i in range(0, num_layers - 1):\n",
    "        d_theta.append(np.zeros([outs[i].shape[1], outs[i+1].shape[1]]))\n",
    "    \n",
    "'''\n",
    "    for i in range(num_layers - 1, -1, -1):\n",
    "        if i == (num_layers - 1):#выходной слой, мы считаем производную от кросс энтропии\n",
    "            for class_no in range(0, num_classes):\n",
    "                d_theta[i][:, class_no] = CEderivative(outs[i-1], y_gt[:, class_no], outs[i][:, class_no])\n",
    "        elif i == 0:\n",
    "            print(np.asarray(outs[i]).shape[1])\n",
    "            for class_no in range(0,np.asarray(outs[i]).shape[1]):#все остальные слои, мы считаем производную от фнкции активации             \n",
    "                d_theta[i][:, class_no] = np.dot(thetas[i], d_theta[i+1])#*sigm_derivative(thetas[i], X)\n",
    "        else:\n",
    "            for class_no in range(0, outs[i].shape[1]):#все остальные слои, мы считаем производную от фнкции активации\n",
    "                d_theta[i][:, class_no] = np.dot(thetas[i], d_theta[i+1])*sigm_derivative(thetas[i], outs[i-1])\n",
    "    '''\n",
    "    return d_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dx_train, dy_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', dx_train.shape)\n",
    "print(dx_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_train = encode_lable(dy_train, 10)\n",
    "y_test = encode_lable(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_train = np.asarray([list(x.flat) for x in dx_train])\n",
    "x_test = np.asarray([list(x.flat) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40000, 3072)\n",
      "y_train shape: (40000, 10)\n",
      "x_val shape: (10000, 3072)\n",
      "y_val shape: (10000, 10)\n",
      "x_test shape: (10000, 3072)\n",
      "y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "p = np.random.permutation(dx_train.shape[0])\n",
    "x_train = dx_train[p[0:int(len(dx_train)*0.8)], :]\n",
    "y_train = dy_train[p[0:int(len(dx_train)*0.8)]]\n",
    "x_val = dx_train[p[int(len(dx_train)*0.8):], :]\n",
    "y_val = dy_train[p[int(len(dx_train)*0.8):]]\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_val shape:\", x_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - np.mean(x_train, axis = 0)) / np.var(x_train, axis = 0)\n",
    "x_val = (x_val - np.mean(x_val, axis = 0)) / np.var(x_val, axis = 0)\n",
    "x_test = (x_test - np.mean(x_test, axis = 0)) / np.var(x_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss : 15.742998990467132\n",
      "Epoch 0/1 ..64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3072,10) into shape (3072)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-241-9774491244d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx_train_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_no\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_no\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0my_train_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_no\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_no\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0md_theta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md_theta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mthetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md_theta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-239-4ecc0930d206>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(X, y_gt, thetas)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mclass_no\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#все остальные слои, мы считаем производную от фнкции активации\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0md_theta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_no\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_theta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#*sigm_derivative(thetas[i], X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mclass_no\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#все остальные слои, мы считаем производную от фнкции активации\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3072,10) into shape (3072)"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "num_epochs = 1\n",
    "alpha = 0.1\n",
    "num_train_samples = x_train.shape[0]\n",
    "num_batches = num_train_samples // batch_size\n",
    "layers_size = [3072 , 64, 10]\n",
    "thetas = np.asarray([np.random.randn(layers_size[i], layers_size[i+1]) for i in range(0, len(layers_size)-1)])\n",
    "y_pred = forward(thetas, x_train)\n",
    "loss_val = loss(y_train, np.asarray(y_pred[len(layers_size) - 2]))\n",
    "print(\"Initial loss :\", loss_val)\n",
    "for i in range(0, num_epochs):\n",
    "    p = np.random.permutation(num_train_samples)\n",
    "    print('Epoch %d/%d ' % (i, num_epochs), end='.')\n",
    "    for batch_no in range(0, num_batches):\n",
    "        if np.mod(batch_no, num_batches // 10) == 0:\n",
    "            print('.', end='')\n",
    "            sys.stdout.flush()\n",
    "        x_train_batch = x_train[p[batch_no * batch_size : (batch_no + 1) * batch_size], :]\n",
    "        y_train_batch = y_train[p[batch_no * batch_size: (batch_no + 1) * batch_size]]\n",
    "        d_theta = backward(x_train_batch, y_train_batch, thetas)\n",
    "        for i in range(0,d_theta.shape[0]):\n",
    "            thetas[i] -= alpha*d_theta[i] \n",
    "    pred_train_probs = forward(thetas, x_train)\n",
    "    pred_train_labels = np.argmax(np.asarray(pred_train_probs[len(layers_size) - 2]), axis=1)\n",
    "    loss_val = loss(y_train, np.asarray(pred_train_probs[len(layers_size) - 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
